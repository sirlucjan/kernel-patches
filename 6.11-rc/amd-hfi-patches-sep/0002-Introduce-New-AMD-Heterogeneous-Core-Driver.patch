From 732fec64f8ea46ecadcb09b2928428b57f05717b Mon Sep 17 00:00:00 2001
From: Peter Jung <admin@ptr1337.dev>
Date: Tue, 27 Aug 2024 16:04:29 +0200
Subject: [PATCH 2/2] Introduce New AMD Heterogeneous Core Driver

The AMD Heterogeneous core design and Hardware Feedback Interface (HFI)
provide behavioral classification and a dynamically updated ranking table
for the scheduler to use when choosing cores for tasks.

Threads are classified during runtime into enumerated classes.
Currently, the driver supports 3 classes (0 through 2). These classes
represent thread performance/power characteristics that may benefit from
special scheduling behaviors. The real-time thread classification is
consumed by the operating system and is used to inform the scheduler of
where the thread should be placed for optimal performance or energy efficiency.

The thread classification helps to select CPU from a ranking table that describes
an efficiency and performance ranking for each classification from two dimensions.

The ranking data provided by the ranking table are numbers ranging from 0 to 255,
where a higher performance value indicates higher performance capability and a higher
efficiency value indicates greater efficiency. All the CPU cores are ranked into
different class IDs. Within each class ranking, the cores may have different ranking
values. Therefore, picking from each classification ID allows the scheduler to select
the best core while threads are classified into the specified workload class.
The cores ranking table is provided with PCCT subspace type 4 shared memory, which
includes the memory base address and length

The series is based off linux-pm/bleeding-edge branch firstly,
will be rebased to platform-drivers-x86 in v2.

Thanks and BR,
Perry.

Perry Yuan (11):
  Documentation: x86: Add AMD Hardware Feedback Interface documentation
  MAINTAINERS: Add maintainer entry for AMD Hardware Feedback Driver
  x86/cpufeatures: add X86_FEATURE_WORKLOAD_CLASS feature bit
  x86/msr-index: define AMD heterogeneous CPU related MSR
  platform/x86: hfi: Introduce AMD Hardware Feedback Interface Driver
  platform/x86/: hfi: parse CPU core ranking data from shared memory
  platform/x86/: hfi: init per-cpu scores for each class
  platform/x86/: hfi: add online and offline callback support
  platform/x86/: hfi: add power management callback
  x86/process: Clear hardware feedback history for AMD processors
  x86/cpu: Enable SD_ASYM_PACKING for DIE Domain on AMD Processors

Signed-off-by: Peter Jung <admin@ptr1337.dev>
---
 Documentation/arch/x86/amd-hfi.rst    | 116 +++++
 Documentation/arch/x86/index.rst      |   1 +
 MAINTAINERS                           |   9 +
 arch/x86/include/asm/cpufeatures.h    |   1 +
 arch/x86/include/asm/hreset.h         |   6 +
 arch/x86/include/asm/msr-index.h      |   5 +
 arch/x86/kernel/cpu/common.c          |  18 +
 arch/x86/kernel/cpu/scattered.c       |   1 +
 arch/x86/kernel/process_32.c          |   3 +
 arch/x86/kernel/process_64.c          |   3 +
 arch/x86/kernel/smpboot.c             |   3 +-
 drivers/platform/x86/amd/Kconfig      |   1 +
 drivers/platform/x86/amd/Makefile     |   1 +
 drivers/platform/x86/amd/hfi/Kconfig  |  21 +
 drivers/platform/x86/amd/hfi/Makefile |   7 +
 drivers/platform/x86/amd/hfi/hfi.c    | 665 ++++++++++++++++++++++++++
 16 files changed, 860 insertions(+), 1 deletion(-)
 create mode 100644 Documentation/arch/x86/amd-hfi.rst
 create mode 100644 arch/x86/include/asm/hreset.h
 create mode 100644 drivers/platform/x86/amd/hfi/Kconfig
 create mode 100644 drivers/platform/x86/amd/hfi/Makefile
 create mode 100644 drivers/platform/x86/amd/hfi/hfi.c

diff --git a/Documentation/arch/x86/amd-hfi.rst b/Documentation/arch/x86/amd-hfi.rst
new file mode 100644
index 000000000..351641ce2
--- /dev/null
+++ b/Documentation/arch/x86/amd-hfi.rst
@@ -0,0 +1,116 @@
+.. SPDX-License-Identifier: GPL-2.0
+
+======================================================================
+Hardware Feedback Interface For Hetero Core Scheduling On AMD Platform
+======================================================================
+
+:Copyright (C) 2024 Advanced Micro Devices, Inc. All Rights Reserved.
+
+:Author: Perry Yuan <perry.yuan@amd.com>
+
+Overview
+--------
+
+AMD Heterogeneous Core implementations are comprised of more than one
+architectural class and CPUs are comprised of cores of various efficiency
+and power capabilities. Power management strategies must be designed to accommodate
+the complexities introduced by incorporating different core types.
+Heterogeneous systems can also extend to more than two architectural classes as well.
+The purpose of the scheduling feedback mechanism is to provide information to
+the operating system scheduler in real time such that the scheduler can direct
+threads to the optimal core.
+
+``Classic cores`` are generally more performant and ``Dense cores`` are generally more
+efficient.
+The goal of AMD's heterogeneous architecture is to attain power benefit by sending
+background thread to the dense cores while sending high priority threads to the classic
+cores. From a performance perspective, sending background threads to dense cores can free
+up power headroom and allow the classic cores to optimally service demanding threads.
+Furthermore, the area optimized nature of the dense cores allows for an increasing
+number of physical cores. This improved core density will have positive multithreaded
+performance impact.
+
+AMD Heterogeneous Core Driver
+-----------------------------
+
+The ``amd_hfi`` driver delivers the operating system a performance and energy efficiency
+capability data for each CPU in the system. The scheduler can use the ranking data
+from the HFI driver to make task placement decisions.
+
+Thread Classification and Ranking Table Interaction
+----------------------------------------------------
+
+The thread classification is used to select into a ranking table that describes
+an efficiency and performance ranking for each classification.
+
+Threads are classified during runtime into enumerated classes. The classes represent
+thread performance/power characteristics that may benefit from special scheduling behaviors.
+The below table depicts an example of thread classification and a preference where a given thread
+should be scheduled based on its thread class. The real time thread classification is consumed
+by the operating system and is used to inform the scheduler of where the thread should be placed.
+
+Thread Classification Example Table
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
++----------+----------------+-------------------------------+---------------------+---------+
+| class ID | Classification | Preferred scheduling behavior | Preemption priority | Counter |
++----------+----------------+-------------------------------+---------------------+---------+
+| 0        | Default        | Performant                    | Highest             |         |
++----------+----------------+-------------------------------+---------------------+---------+
+| 1        | Non-scalable   | Efficient                     | Lowest              | PMCx1A1 |
++----------+----------------+-------------------------------+---------------------+---------+
+| 2        | I/O bound      | Efficient                     | Lowest              | PMCx044 |
++----------+----------------+-------------------------------+---------------------+---------+
+
+
+AMD Hardware Feedback Interface
+--------------------------------
+
+The Hardware Feedback Interface provides to the operating system information
+about the performance and energy efficiency of each CPU in the system. Each
+capability is given as a unit-less quantity in the range [0-255]. A higher
+performance value indicates higher performance capability, and a higher
+efficiency value indicates more efficiency. Energy efficiency and performance
+are reported in separate capabilities in the shared memory based ranking table.
+
+These capabilities may change at runtime as a result of changes in the
+operating conditions of the system or the action of external factors.
+Power Management FW is responsible for detecting events that would require
+a reordering of the performance and efficiency ranking. Table updates would
+happen relatively infrequently and occur on the time scale of seconds or more.
+
+The mechanism used to trigger a table update like below events:
+    * Thermal Stress Events
+    * Silent Compute
+    * Extreme Low Battery Scenarios
+
+The kernel or a userspace policy daemon can use these capabilities to modify
+task placement decisions. For instance, if either the performance or energy
+capabilities of a given logical processor becomes zero, it is an indication that
+the hardware recommends to the operating system to not schedule any tasks on
+that processor for performance or energy efficiency reasons, respectively.
+
+Implementation details for Linux
+--------------------------------
+
+The implementation of threads scheduling consists of the following steps:
+
+1. A thread is spawned and scheduled to the ideal core using the default
+   heterogeneous scheduling policy.
+2. The processor profiles thread execution and assigns an enumerated classification ID.
+   This classification is communicated to the OS via logical processor scope MSR.
+3. During the thread context switch out the operating system consumes the workload(WL)
+   classification which resides in a logical processor scope MSR.
+4. The OS triggers the hardware to clear its history by writing to an MSR,
+   after consuming the WL classification and before switching in the new thread.
+5. If due to the classification, ranking table, and processor availability,
+   the thread is not on its ideal processor, the OS will then consider scheduling
+   the thread on its ideal processor (if available).
+
+Ranking Table update
+---------------------------
+The power management firmware issues an platform interrupt after updating the ranking
+table and is ready for the operating system to consume it. CPUs receive such interrupt
+and read new ranking table from shared memory which PCCT table has provided, then
+``amd_hfi`` driver parse the new table to provide new consume data for scheduling decisions.
+
+
diff --git a/Documentation/arch/x86/index.rst b/Documentation/arch/x86/index.rst
index 8ac64d7de..7f47229f3 100644
--- a/Documentation/arch/x86/index.rst
+++ b/Documentation/arch/x86/index.rst
@@ -43,3 +43,4 @@ x86-specific Documentation
    features
    elf_auxvec
    xstate
+   amd_hfi
diff --git a/MAINTAINERS b/MAINTAINERS
index 878dcd23b..04030af97 100644
--- a/MAINTAINERS
+++ b/MAINTAINERS
@@ -1052,6 +1052,15 @@ F:	arch/x86/include/asm/amd_hsmp.h
 F:	arch/x86/include/uapi/asm/amd_hsmp.h
 F:	drivers/platform/x86/amd/hsmp.c
 
+AMD HETERO CORE HARDWARE FEEDBACK DRIVER
+M:	Perry Yuan <perry.yuan@amd.com>
+M:	Mario Limonciello <mario.limonciello@amd.com>
+L:	platform-driver-x86@vger.kernel.org
+S:	Supported
+B:	https://gitlab.freedesktop.org/drm/amd/-/issues
+F:	drivers/platform/x86/amd/hfi/
+F:	Documentation/arch/x86/amd-hfi.rst
+
 AMD IOMMU (AMD-VI)
 M:	Joerg Roedel <joro@8bytes.org>
 R:	Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>
diff --git a/arch/x86/include/asm/cpufeatures.h b/arch/x86/include/asm/cpufeatures.h
index eff4587ed..f29856ae9 100644
--- a/arch/x86/include/asm/cpufeatures.h
+++ b/arch/x86/include/asm/cpufeatures.h
@@ -474,6 +474,7 @@
 #define X86_FEATURE_CLEAR_BHB_LOOP_ON_VMEXIT (21*32+ 4) /* Clear branch history at vmexit using SW loop */
 #define X86_FEATURE_FAST_CPPC		(21*32 + 5) /* AMD Fast CPPC */
 #define X86_FEATURE_HETERO_CORE_TOPOLOGY       (21*32+ 6) /* "" Heterogeneous Core Topology */
+#define X86_FEATURE_WORKLOAD_CLASS		(21*32+ 7) /* Workload Classification */
 
 /*
  * BUG word(s)
diff --git a/arch/x86/include/asm/hreset.h b/arch/x86/include/asm/hreset.h
new file mode 100644
index 000000000..ae1f72602
--- /dev/null
+++ b/arch/x86/include/asm/hreset.h
@@ -0,0 +1,6 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef _ASM_X86_HRESET_H
+
+void reset_hardware_history_hetero(void);
+
+#endif /* _ASM_X86_HRESET_H */
diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 82c6a4d35..a70c14757 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -690,6 +690,11 @@
 #define MSR_AMD64_PERF_CNTR_GLOBAL_CTL		0xc0000301
 #define MSR_AMD64_PERF_CNTR_GLOBAL_STATUS_CLR	0xc0000302
 
+/* AMD Hardware Feedback Support MSRs */
+#define AMD_WORKLOAD_CLASS_CONFIG      0xc0000500
+#define AMD_WORKLOAD_CLASS_ID          0xc0000501
+#define AMD_WORKLOAD_HRST              0xc0000502
+
 /* AMD Last Branch Record MSRs */
 #define MSR_AMD64_LBR_SELECT			0xc000010e
 
diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c
index d4e539d4e..2ef34669f 100644
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@ -57,6 +57,7 @@
 #include <asm/mce.h>
 #include <asm/msr.h>
 #include <asm/cacheinfo.h>
+#include <asm/hreset.h>
 #include <asm/memtype.h>
 #include <asm/microcode.h>
 #include <asm/intel-family.h>
@@ -398,6 +399,14 @@ static __always_inline void setup_umip(struct cpuinfo_x86 *c)
 	cr4_clear_bits(X86_CR4_UMIP);
 }
 
+static u32 hardware_history_features __ro_after_init;
+
+static __always_inline void setup_hreset(struct cpuinfo_x86 *c)
+{
+	if (cpu_feature_enabled(X86_FEATURE_WORKLOAD_CLASS))
+		hardware_history_features = 1;
+}
+
 /* These bits should not change their value after CPU init is finished. */
 static const unsigned long cr4_pinned_mask = X86_CR4_SMEP | X86_CR4_SMAP | X86_CR4_UMIP |
 					     X86_CR4_FSGSBASE | X86_CR4_CET | X86_CR4_FRED;
@@ -1839,6 +1848,7 @@ static void identify_cpu(struct cpuinfo_x86 *c)
 	setup_smep(c);
 	setup_smap(c);
 	setup_umip(c);
+	setup_hreset(c);
 
 	/* Enable FSGSBASE instructions if available. */
 	if (cpu_has(c, X86_FEATURE_FSGSBASE)) {
@@ -2392,3 +2402,11 @@ void __init arch_cpu_finalize_init(void)
 	 */
 	mem_encrypt_init();
 }
+
+__always_inline void reset_hardware_history_hetero()
+{
+	if (!hardware_history_features)
+		return;
+
+	wrmsrl(AMD_WORKLOAD_HRST, 0x1);
+}
diff --git a/arch/x86/kernel/cpu/scattered.c b/arch/x86/kernel/cpu/scattered.c
index 6b3477503..8343e2e44 100644
--- a/arch/x86/kernel/cpu/scattered.c
+++ b/arch/x86/kernel/cpu/scattered.c
@@ -49,6 +49,7 @@ static const struct cpuid_bit cpuid_bits[] = {
 	{ X86_FEATURE_MBA,		CPUID_EBX,  6, 0x80000008, 0 },
 	{ X86_FEATURE_SMBA,		CPUID_EBX,  2, 0x80000020, 0 },
 	{ X86_FEATURE_BMEC,		CPUID_EBX,  3, 0x80000020, 0 },
+	{ X86_FEATURE_WORKLOAD_CLASS,   CPUID_EAX,  22, 0x80000021, 0 },
 	{ X86_FEATURE_PERFMON_V2,	CPUID_EAX,  0, 0x80000022, 0 },
 	{ X86_FEATURE_AMD_LBR_V2,	CPUID_EAX,  1, 0x80000022, 0 },
 	{ X86_FEATURE_AMD_LBR_PMC_FREEZE,	CPUID_EAX,  2, 0x80000022, 0 },
diff --git a/arch/x86/kernel/process_32.c b/arch/x86/kernel/process_32.c
index 0917c7f25..6a3a1339f 100644
--- a/arch/x86/kernel/process_32.c
+++ b/arch/x86/kernel/process_32.c
@@ -52,6 +52,7 @@
 #include <asm/switch_to.h>
 #include <asm/vm86.h>
 #include <asm/resctrl.h>
+#include <asm/hreset.h>
 #include <asm/proto.h>
 
 #include "process.h"
@@ -213,6 +214,8 @@ __switch_to(struct task_struct *prev_p, struct task_struct *next_p)
 	/* Load the Intel cache allocation PQR MSR. */
 	resctrl_sched_in(next_p);
 
+	reset_hardware_history_hetero();
+
 	return prev_p;
 }
 
diff --git a/arch/x86/kernel/process_64.c b/arch/x86/kernel/process_64.c
index 6d3d20e3e..096ac69bb 100644
--- a/arch/x86/kernel/process_64.c
+++ b/arch/x86/kernel/process_64.c
@@ -54,6 +54,7 @@
 #include <asm/xen/hypervisor.h>
 #include <asm/vdso.h>
 #include <asm/resctrl.h>
+#include <asm/hreset.h>
 #include <asm/unistd.h>
 #include <asm/fsgsbase.h>
 #include <asm/fred.h>
@@ -709,6 +710,8 @@ __switch_to(struct task_struct *prev_p, struct task_struct *next_p)
 	/* Load the Intel cache allocation PQR MSR. */
 	resctrl_sched_in(next_p);
 
+	reset_hardware_history_hetero();
+
 	return prev_p;
 }
 
diff --git a/arch/x86/kernel/smpboot.c b/arch/x86/kernel/smpboot.c
index 0c3520732..16a893322 100644
--- a/arch/x86/kernel/smpboot.c
+++ b/arch/x86/kernel/smpboot.c
@@ -496,7 +496,8 @@ static int x86_cluster_flags(void)
 
 static int x86_die_flags(void)
 {
-	if (cpu_feature_enabled(X86_FEATURE_HYBRID_CPU))
+	if (cpu_feature_enabled(X86_FEATURE_HYBRID_CPU) ||
+			cpu_feature_enabled(X86_FEATURE_HETERO_CORE_TOPOLOGY))
 	       return x86_sched_itmt_flags();
 
 	return 0;
diff --git a/drivers/platform/x86/amd/Kconfig b/drivers/platform/x86/amd/Kconfig
index f88682d36..c3f69dbe3 100644
--- a/drivers/platform/x86/amd/Kconfig
+++ b/drivers/platform/x86/amd/Kconfig
@@ -5,6 +5,7 @@
 
 source "drivers/platform/x86/amd/pmf/Kconfig"
 source "drivers/platform/x86/amd/pmc/Kconfig"
+source "drivers/platform/x86/amd/hfi/Kconfig"
 
 config AMD_HSMP
 	tristate "AMD HSMP Driver"
diff --git a/drivers/platform/x86/amd/Makefile b/drivers/platform/x86/amd/Makefile
index dcec0a46f..2676fc81f 100644
--- a/drivers/platform/x86/amd/Makefile
+++ b/drivers/platform/x86/amd/Makefile
@@ -9,3 +9,4 @@ amd_hsmp-y			:= hsmp.o
 obj-$(CONFIG_AMD_HSMP)		+= amd_hsmp.o
 obj-$(CONFIG_AMD_PMF)		+= pmf/
 obj-$(CONFIG_AMD_WBRF)		+= wbrf.o
+obj-$(CONFIG_AMD_HFI)		+= hfi/
diff --git a/drivers/platform/x86/amd/hfi/Kconfig b/drivers/platform/x86/amd/hfi/Kconfig
new file mode 100644
index 000000000..4671cc103
--- /dev/null
+++ b/drivers/platform/x86/amd/hfi/Kconfig
@@ -0,0 +1,21 @@
+# SPDX-License-Identifier: GPL-2.0-only
+#
+# AMD Hardware Feedback Interface Driver
+#
+
+config AMD_HFI
+	bool "AMD Hetero Core Hardware Feedback Driver"
+	depends on ACPI
+	depends on CPU_SUP_AMD
+	select IPC_CLASSES
+	help
+	 Select this option to enable the AMD Heterogeneous Core Hardware Feedback Interface. If
+	 selected, hardware provides runtime thread classification guidance to the operating system
+	 on the performance and energy efficiency capabilities of each heterogeneous CPU core.
+	 These capabilities may vary due to the inherent differences in the core types and can
+	 also change as a result of variations in the operating conditions of the system such
+	 as power and thermal limits. If selected, the kernel relays updates in heterogeneous
+	 CPUs' capabilities to userspace, allowing for more optimal task scheduling and
+	 resource allocation, leveraging the diverse set of cores available.
+
+
diff --git a/drivers/platform/x86/amd/hfi/Makefile b/drivers/platform/x86/amd/hfi/Makefile
new file mode 100644
index 000000000..672c6ac10
--- /dev/null
+++ b/drivers/platform/x86/amd/hfi/Makefile
@@ -0,0 +1,7 @@
+# SPDX-License-Identifier: GPL-2.0
+#
+# AMD Hardware Feedback Interface Driver
+#
+
+obj-$(CONFIG_AMD_HFI) += amd_hfi.o
+amd_hfi-objs := hfi.o
diff --git a/drivers/platform/x86/amd/hfi/hfi.c b/drivers/platform/x86/amd/hfi/hfi.c
new file mode 100644
index 000000000..c3da2edf8
--- /dev/null
+++ b/drivers/platform/x86/amd/hfi/hfi.c
@@ -0,0 +1,665 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * AMD Hardware Feedback Interface Driver
+ *
+ * Copyright (C) 2024 Advanced Micro Devices, Inc. All Rights Reserved.
+ *
+ * Author: Perry Yuan <Perry.Yuan@amd.com>
+ *
+ */
+
+#define pr_fmt(fmt)  "amd-hfi: " fmt
+
+#include <linux/acpi.h>
+#include <linux/bitops.h>
+#include <linux/cpu.h>
+#include <linux/cpumask.h>
+#include <linux/gfp.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mailbox_client.h>
+#include <linux/mutex.h>
+#include <linux/percpu-defs.h>
+#include <linux/platform_device.h>
+#include <linux/printk.h>
+#include <linux/smp.h>
+#include <linux/string.h>
+#include <linux/topology.h>
+#include <linux/workqueue.h>
+
+#include <asm/cpu_device_id.h>
+
+#include <acpi/pcc.h>
+#include <acpi/cppc_acpi.h>
+
+#define AMD_HFI_DRIVER		"amd_hfi"
+#define AMD_HETERO_CPUID_27	0x80000027
+#define AMD_HETERO_RANKING_TABLE_VER	2
+static struct platform_device *device;
+
+/**
+ * struct amd_core_rank_table - HFI capabilities for the logical
+ * processors in the memory mappep table.
+ *
+ * @signature:	The PCC signature. The signature of a subspace is computed by
+ *		a bitwise of the value 0x50434300 with the subspace ID.
+ * @flags:	Notify on completion
+ * @length:	Length of payload being transmitted including command field
+ * @command:	Command being sent over the subspace
+ * @version_number:		Version number of the table
+ * @n_logical_processors:	Number of logical processors
+ * @n_capabilities:		Number of ranking dimensions (performance, efficiency, etc)
+ * @table_update_context:	Command being sent over the subspace
+ * @n_bitmaps:			Number of 32-bit bitmaps to enumerate all the APIC IDs
+ *				This is based on the maximum apic ID enumerated in the system
+ * @reserved:			The 24bit spare
+ * @bitmap_of_apic_id0:		Bit Map of enabled logical processors APIC ID for 31:0
+ * @bitmap_of_apic_id1:		Bit Map of enabled logical processors APIC ID for 64:32
+ * @n_classes:			Number of workload class
+ * @dynamic_rank_feature:	Table update mode
+ * @diagnostics:		Reserved space for diagnostics
+ * @timestamp:			Timestamp for last table update
+ * @table_size:			Table length of shared memory
+ * @shmem_info:			The table data read from shared memory
+ * @bitmap_data:		Bitmap data read from table
+ * @max_index:			The max data array in the table
+ *
+ * A memory mapped table is used to express the capabilities of each logical
+ * processor for each thread classification. with dynamic table update feature
+ * supported, the table will be notified to update for all the cores while system
+ * running, each table update can reorder the cores for much better performance and
+ * power efficiency.
+ *
+ */
+struct amd_hfi_metadata {
+	u32	signature;
+	u32	flags:1;
+	u32	length;
+	u32	command;
+	u8	version_number;
+	u8	n_logical_processors;
+	u8	n_capabilities;
+	u8	table_update_context;
+	u8	n_bitmaps;
+	u32	reserved:24;
+	u32	bitmap_of_apic_id0;
+	u32	bitmap_of_apic_id1;
+	u8	n_classes;
+	bool	dynamic_rank_feature;
+	int	diagnostics;
+	u64	timestamp;
+	u64	table_size;
+	u32	shmem_info[64];
+	u32	bitmap_data;
+	u32	max_index;
+};
+
+struct amd_hfi_data {
+	const char	*name;
+	struct device	*dev;
+	struct mutex	lock;
+	acpi_handle	dhandle;
+
+	/* PCCT table related*/
+	int		plat_irq;
+	struct pcc_mbox_chan	*pcc_chan;
+	void __iomem		*pcc_comm_addr;
+	struct completion	done;
+	struct mbox_client	cl;
+	raw_spinlock_t		table_lock;
+	struct acpi_subtable_header	*pcct_entry;
+	struct amd_hfi_metadata		*hfi_meta;
+	raw_spinlock_t		hfi_data_lock;
+};
+
+/**
+ * struct amd_hfi_classes - HFI class capabilities per CPU
+ * @perf:		Performance capability
+ * @eff:		Power efficiency capability
+ *
+ * Capabilities of a logical processor in the rank table. These capabilities are
+ * unitless and specific to each HFI class.
+ */
+struct amd_hfi_classes {
+	u32	perf;
+	u32	eff;
+} __packed;
+
+/**
+ * struct amd_hfi_cpuinfo - HFI workload class info per CPU
+ * @cpu:		cpu index
+ * @cpus:		cpu mask of cpus
+ * @apic_id:		apic id of the current cpu
+ * @class_index:	workload class ID index
+ * @nr_classa:		max number of workload class supported
+ * @amd_hfi_classes:	current cpu workload class ranking data
+ *
+ * Parameters of a logical processor linked with hardware feedback class
+ */
+struct amd_hfi_cpuinfo {
+	int		cpu;
+	cpumask_var_t	cpus;
+	u32		apic_id;
+	s16		class_index;
+	u8		nr_class;
+	struct amd_hfi_classes	*amd_hfi_classes;
+};
+
+static DEFINE_PER_CPU(struct amd_hfi_cpuinfo, amd_hfi_cpuinfo) = {.class_index = -1};
+
+static DEFINE_MUTEX(hfi_cpuinfo_lock);
+static int __percpu *amd_hfi_ipcc_scores;
+
+static int amd_set_hfi_ipcc_score(struct amd_hfi_cpuinfo *info, int cpu);
+static int update_hfi_ipcc_scores(struct amd_hfi_data *amd_hfi_data);
+static int amd_hfi_set_state(unsigned int cpu, bool state);
+
+static int find_cpu_index_by_apicid(unsigned int target_apicid)
+{
+	int cpu_index;
+
+	for_each_possible_cpu(cpu_index) {
+		struct cpuinfo_x86 *info = &cpu_data(cpu_index);
+
+		if (info->topo.apicid == target_apicid) {
+			pr_debug(" match apic id %d for cpu index: %d",
+						info->topo.apicid, cpu_index);
+			return cpu_index;
+		}
+	}
+
+	return -ENODEV;
+}
+
+static int amd_hfi_fill_metadata(struct amd_hfi_data *amd_hfi_data)
+{
+	struct pcc_mbox_chan *pcc_chan = amd_hfi_data->pcc_chan;
+	struct acpi_subtable_header *pcct_entry = amd_hfi_data->pcct_entry;
+	struct acpi_pcct_ext_pcc_slave *pcct_ext =
+		(struct acpi_pcct_ext_pcc_slave *)pcct_entry;
+	struct amd_hfi_metadata *meta = amd_hfi_data->hfi_meta;
+	u32 header_index = 0, data_index = 0;
+	struct amd_hfi_cpuinfo *info;
+	u32 offset, offset_begin;
+	void __iomem *pcc_comm_addr;
+	int idx, ret, length;
+	u32 *shmem_info;
+
+	length = pcct_ext->length;
+	if (length <= 0) {
+		pr_err("length is less than min table length required\n");
+		return -EINVAL;
+	}
+
+	shmem_info = devm_kmalloc_array(amd_hfi_data->dev, length, sizeof(u32), GFP_KERNEL);
+	if (!shmem_info) {
+		pr_err("failed to allocate memory %x\n", length);
+		return -ENOMEM;
+	}
+
+	pcc_chan->shmem_base_addr = pcct_ext->base_address;
+	pcc_chan->shmem_size = pcct_ext->length;
+
+	amd_hfi_data->plat_irq = pcct_ext->platform_interrupt;
+	if (amd_hfi_data->plat_irq < 0) {
+		pr_err("invalid irq allocated in pcct table\n");
+		return -EINVAL;
+	}
+
+	pcc_comm_addr = acpi_os_ioremap(pcc_chan->shmem_base_addr, pcc_chan->shmem_size);
+	if (!pcc_comm_addr) {
+		pr_err("failed to ioremap PCC common region mem\n");
+		return -ENOMEM;
+	}
+
+	raw_spin_lock(&amd_hfi_data->table_lock);
+
+	memcpy_fromio(shmem_info, (u32 __iomem *)pcc_comm_addr, length);
+
+	/* extended PCC subspace shared memory region */
+	meta->signature = shmem_info[header_index];
+	meta->flags = shmem_info[++header_index];
+	meta->length = shmem_info[++header_index];
+	meta->command = shmem_info[++header_index];
+	idx = header_index + 1;
+
+	/* shared memory region for cores ranking data */
+	meta->version_number = shmem_info[idx] & 0xFF;
+	meta->n_logical_processors = (shmem_info[idx] >> 8) & 0xFF;
+	meta->n_capabilities = (shmem_info[idx] >> 16) & 0xFF;
+	meta->table_update_context = (shmem_info[idx] >> 24) & 0xFF;
+	meta->n_bitmaps = shmem_info[++idx] & 0xFF;
+	meta->n_classes = (shmem_info[idx] >> 8) & 0xFF;
+	meta->bitmap_data = shmem_info[++idx];
+	meta->max_index = meta->n_bitmaps * 32;
+
+	if (meta->version_number == AMD_HETERO_RANKING_TABLE_VER)
+		offset_begin = idx + 1;
+
+	for (u32 bit_idx = 0; bit_idx < meta->max_index; bit_idx++) {
+		if (meta->bitmap_data & (1u << bit_idx)) {
+			int cpu_index = find_cpu_index_by_apicid(bit_idx);
+			if (cpu_index < 0) {
+				ret = -ENODEV;
+				goto err_map;
+			}
+
+			info = per_cpu_ptr(&amd_hfi_cpuinfo, cpu_index);
+
+			offset = data_index * 6 + offset_begin;
+			for (int i = 0; i < meta->n_classes; i++) {
+				info->amd_hfi_classes[i].eff = shmem_info[offset + 2 * i];
+				info->amd_hfi_classes[i].perf = shmem_info[offset + 2 * i + 1];
+			}
+		} else {
+			continue;
+		}
+		data_index++;
+	}
+	raw_spin_unlock(&amd_hfi_data->table_lock);
+	iounmap(pcc_comm_addr);
+
+	return 0;
+
+err_map:
+	raw_spin_unlock(&amd_hfi_data->table_lock);
+	return ret;
+}
+
+static int amd_hfi_alloc_class_data(struct platform_device *pdev)
+{
+	struct amd_hfi_cpuinfo *hfi_cpuinfo;
+	struct device *dev = &pdev->dev;
+	int idx;
+	int nr_class_id;
+
+	nr_class_id = cpuid_eax(AMD_HETERO_CPUID_27);
+	if (nr_class_id < 0 || nr_class_id > 255) {
+		dev_warn(dev, "failed to get supported class number from CPUID %d\n",
+				AMD_HETERO_CPUID_27);
+		return -EINVAL;
+	}
+
+	for_each_possible_cpu(idx) {
+		hfi_cpuinfo = per_cpu_ptr(&amd_hfi_cpuinfo, idx);
+		hfi_cpuinfo->amd_hfi_classes = devm_kmalloc(dev, nr_class_id *
+				sizeof(struct amd_hfi_classes), GFP_KERNEL);
+		if (!hfi_cpuinfo->amd_hfi_classes) {
+			pr_err("failed to allocate memory\n");
+			return -ENOMEM;
+		}
+
+		hfi_cpuinfo->nr_class = nr_class_id;
+	}
+
+	return 0;
+}
+
+static void amd_hfi_remove(struct platform_device *pdev)
+{
+	struct amd_hfi_data *dev = platform_get_drvdata(pdev);
+
+	mutex_destroy(&dev->lock);
+}
+
+static int amd_hfi_pm_resume(struct device *dev)
+{
+	int cpu, err;
+
+	for_each_present_cpu(cpu) {
+		err = amd_hfi_set_state(cpu, true);
+		if (err < 0) {
+			dev_err(dev, "failed to enable workload class config: %d\n", err);
+			return err;
+		}
+	}
+
+	return 0;
+}
+
+static int amd_hfi_pm_suspend(struct device *dev)
+{
+	int err, cpu;
+
+	for_each_possible_cpu(cpu) {
+		err = amd_hfi_set_state(cpu, false);
+		if (err < 0) {
+			dev_err(dev, "failed to disable workload class config: %d\n", err);
+			return err;
+		}
+	}
+
+	return 0;
+}
+
+static DEFINE_SIMPLE_DEV_PM_OPS(amd_hfi_pm_ops,
+		amd_hfi_pm_suspend, amd_hfi_pm_resume);
+
+static int amd_set_hfi_ipcc_score(struct amd_hfi_cpuinfo *hfi_cpuinfo, int cpu)
+{
+	int i, *hfi_scores;
+	u8 nr_classes = hfi_cpuinfo->nr_class;
+
+	hfi_scores = per_cpu_ptr(amd_hfi_ipcc_scores, cpu);
+	if (!hfi_scores)
+		return -ENODEV;
+
+	for (i = 0;  i < nr_classes; i++)
+		WRITE_ONCE(hfi_scores[i], hfi_cpuinfo->amd_hfi_classes[i].perf);
+
+	return 0;
+}
+
+static int amd_hfi_set_state(unsigned int cpu, bool state)
+{
+	int ret;
+
+	ret = wrmsrl_on_cpu(cpu, AMD_WORKLOAD_CLASS_CONFIG, state);
+	if (ret)
+		return ret;
+
+	return wrmsrl_on_cpu(cpu, AMD_WORKLOAD_HRST, 0x1);
+}
+
+/*
+ * amd_hfi_online() - Enable workload classification on @cpu
+ * @cpu: CPU in which the workload classification will be enabled
+ *
+ */
+static int amd_hfi_online(unsigned int cpu)
+{
+	struct amd_hfi_cpuinfo *hfi_info = per_cpu_ptr(&amd_hfi_cpuinfo, cpu);
+	struct amd_hfi_classes *hfi_classes;
+	int ret;
+
+	if (WARN_ON_ONCE(!hfi_info))
+		return -EINVAL;
+
+	if (!zalloc_cpumask_var(&hfi_info->cpus, GFP_KERNEL))
+		return -ENOMEM;
+
+	mutex_lock(&hfi_cpuinfo_lock);
+	cpumask_set_cpu(cpu, hfi_info->cpus);
+
+	/*
+	 * Check if @cpu as an associated, initialized and ranking data must be filled
+	 */
+	hfi_classes = hfi_info->amd_hfi_classes;
+	if (!hfi_classes)
+		goto unlock;
+
+	/* Enable the workload classification interface */
+	ret = amd_hfi_set_state(cpu, true);
+	if (ret)
+		pr_err("wct enable failed for cpu %d\n", cpu);
+
+	mutex_unlock(&hfi_cpuinfo_lock);
+	return 0;
+
+unlock:
+	free_cpumask_var(hfi_info->cpus);
+	mutex_unlock(&hfi_cpuinfo_lock);
+	return ret;
+}
+
+/*
+ * amd_hfi_offline() - Disable workload classification on @cpu
+ * @cpu: CPU in which the workload classification will be disabled
+ *
+ * Remove @cpu from those covered by its HFI instance.
+ *
+ */
+static int amd_hfi_offline(unsigned int cpu)
+{
+	struct amd_hfi_cpuinfo *hfi_info = &per_cpu(amd_hfi_cpuinfo, cpu);
+	int ret;
+
+	if (WARN_ON_ONCE(!hfi_info))
+		return -EINVAL;
+
+	mutex_lock(&hfi_cpuinfo_lock);
+
+	/* Disable the workload classification interface */
+	ret = amd_hfi_set_state(cpu, false);
+	if (ret)
+		pr_err("wct disable failed for cpu %d\n", cpu);
+
+	mutex_unlock(&hfi_cpuinfo_lock);
+
+	free_cpumask_var(hfi_info->cpus);
+
+	return 0;
+}
+
+static int update_hfi_ipcc_scores(struct amd_hfi_data *amd_hfi_data)
+{
+	int cpu;
+	int ret;
+
+	raw_spin_lock_irq(&amd_hfi_data->hfi_data_lock);
+	for_each_online_cpu(cpu) {
+		struct amd_hfi_cpuinfo *hfi_cpuinfo = per_cpu_ptr(&amd_hfi_cpuinfo, cpu);
+
+		ret = amd_set_hfi_ipcc_score(hfi_cpuinfo, cpu);
+		if (ret)
+			return ret;
+	}
+	raw_spin_unlock_irq(&amd_hfi_data->hfi_data_lock);
+
+	return 0;
+}
+
+static int amd_hfi_metadata_parser(struct platform_device *pdev,
+		struct amd_hfi_data *amd_hfi_data)
+{
+	struct mbox_chan *pcc_mbox_channels;
+	struct pcc_mbox_chan *pcc_chan;
+	struct acpi_subtable_header *pcct_entry;
+	struct acpi_table_header *pcct_tbl;
+	struct device *dev = &pdev->dev;
+	acpi_status status;
+	int ret = 0, count = 1;
+
+	status = acpi_get_table(ACPI_SIG_PCCT, 0, &pcct_tbl);
+	if (ACPI_FAILURE(status) || !pcct_tbl) {
+		pr_err("acpi_get_table failed!\n");
+		return -ENODEV;
+	}
+
+	pcc_mbox_channels = devm_kcalloc(dev, count,
+			sizeof(*pcc_mbox_channels), GFP_KERNEL);
+	if (!pcc_mbox_channels) {
+		ret = -ENOMEM;
+		goto exit_err;
+	}
+
+	pcc_chan = devm_kcalloc(dev, count, sizeof(*pcc_chan), GFP_KERNEL);
+	if (!pcc_chan) {
+		ret = -ENOMEM;
+		goto exit_err;
+	}
+
+	/* get pointer to the first PCC subspace entry */
+	pcct_entry = (struct acpi_subtable_header *) (
+			(unsigned long) pcct_tbl + sizeof(struct acpi_table_pcct));
+
+	pcc_chan->mchan = &pcc_mbox_channels[0];
+
+	amd_hfi_data->pcc_chan = pcc_chan;
+	amd_hfi_data->pcct_entry = pcct_entry;
+
+	/* parse the shared memory info from the pcct table */
+	ret = amd_hfi_fill_metadata(amd_hfi_data);
+	if (ret) {
+		pr_err("failed to parse core ranking table\n");
+		ret = -ENODATA;
+	}
+
+exit_err:
+	acpi_put_table(pcct_tbl);
+	return ret;
+}
+
+static int alloc_amd_hfi_ipcc_scores(struct amd_hfi_data *amd_hfi_data)
+{
+	struct amd_hfi_metadata *hfi_meta = amd_hfi_data->hfi_meta;
+
+	amd_hfi_ipcc_scores = __alloc_percpu(sizeof(*amd_hfi_ipcc_scores) *
+			hfi_meta->n_classes,
+			sizeof(*amd_hfi_ipcc_scores));
+	if (WARN_ON(!amd_hfi_ipcc_scores))
+		return -ENOMEM;
+
+	return 0;
+}
+
+static const struct acpi_device_id amd_hfi_platform_match[] = {
+	{ "AMDI0104", 0},
+	{ }
+};
+MODULE_DEVICE_TABLE(acpi, amd_hfi_platform_match);
+
+static int amd_hfi_probe(struct platform_device *pdev)
+{
+	struct amd_hfi_data *amd_hfi_data;
+	const struct acpi_device_id *id;
+	struct acpi_device *acpi_dev;
+	acpi_handle dhandle;
+	int ret;
+
+	id = acpi_match_device(amd_hfi_platform_match, &pdev->dev);
+	if (!id)
+		return -ENODEV;
+
+	amd_hfi_data = devm_kzalloc(&pdev->dev,
+			sizeof(*amd_hfi_data), GFP_KERNEL);
+	if (!amd_hfi_data)
+		return -ENOMEM;
+
+	amd_hfi_data->hfi_meta = devm_kzalloc(&pdev->dev,
+					sizeof(*amd_hfi_data->hfi_meta), GFP_KERNEL);
+	if (!amd_hfi_data->hfi_meta)
+		return -ENOMEM;
+	amd_hfi_data->dev = &pdev->dev;
+	dhandle = ACPI_HANDLE(&pdev->dev);
+	if (!dhandle) {
+		dev_err(&pdev->dev, "dhandle is null\n");
+		return -ENODEV;
+	}
+
+	acpi_dev = acpi_fetch_acpi_dev(dhandle);
+	if (!acpi_dev)
+		return -ENODEV;
+
+	amd_hfi_data->dhandle = dhandle;
+
+	raw_spin_lock_init(&amd_hfi_data->table_lock);
+	raw_spin_lock_init(&amd_hfi_data->hfi_data_lock);
+	mutex_init(&amd_hfi_data->lock);
+
+	platform_set_drvdata(pdev, amd_hfi_data);
+
+	/* alloc data array for hardware feedback class data */
+	ret = amd_hfi_alloc_class_data(pdev);
+	if (ret)
+		return -ENOMEM;
+
+	ret = amd_hfi_metadata_parser(pdev, amd_hfi_data);
+	if (ret) {
+		dev_err(&pdev->dev, "failed to parse PCCT table data with %d.\n", ret);
+		goto err_exit;
+	}
+
+	amd_hfi_data->hfi_meta->dynamic_rank_feature =
+					cpuid_ebx(AMD_HETERO_CPUID_27) & 0xF;
+
+	if (alloc_amd_hfi_ipcc_scores(amd_hfi_data))
+		goto err_exit;
+
+	ret = update_hfi_ipcc_scores(amd_hfi_data);
+	if (ret)
+		goto err_exit;
+
+	ret = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, "x86/amd_hfi:online",
+			amd_hfi_online,
+			amd_hfi_offline);
+	if (ret < 0) {
+		pr_warn("failed to setup cpuhp state! (%d)\n", ret);
+		return ret;
+	}
+
+	dev_dbg(&pdev->dev, "%s driver registered.\n", pdev->name);
+
+	return 0;
+
+err_exit:
+	return ret;
+}
+
+static struct platform_driver amd_hfi_driver = {
+	.driver = {
+		.name = AMD_HFI_DRIVER,
+		.owner = THIS_MODULE,
+		.pm	= &amd_hfi_pm_ops,
+		.acpi_match_table = ACPI_PTR(amd_hfi_platform_match),
+	},
+	.probe = amd_hfi_probe,
+	.remove_new = amd_hfi_remove,
+};
+
+static int amd_platform_hfi_init(void)
+{
+	struct platform_device *pdev;
+	int ret;
+
+	pdev = platform_device_register_simple(AMD_HFI_DRIVER, -1, NULL, 0);
+	if (IS_ERR(pdev)) {
+		pr_err("unable to register hfi platform device\n");
+		return PTR_ERR(pdev);
+	}
+
+	ret = platform_driver_register(&amd_hfi_driver);
+	if (ret) {
+		pr_err("Failed to register hfi driver\n");
+	}
+
+	return ret;
+}
+
+static int __init amd_hfi_init(void)
+{
+	int ret;
+
+	if (acpi_disabled)
+		return -ENODEV;
+
+	if (!boot_cpu_has(X86_FEATURE_HETERO_CORE_TOPOLOGY)) {
+		pr_debug("amd Hetero Core feature reporting not supported!\n");
+		return -ENODEV;
+	}
+
+	if (!boot_cpu_has(X86_FEATURE_WORKLOAD_CLASS)) {
+		pr_debug("workload class reporting not supported!\n");
+		return -ENODEV;
+	}
+
+	/* platform PCC Subspace Type 4 driver init */
+	ret = amd_platform_hfi_init();
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static __exit void amd_hfi_exit(void)
+{
+	platform_device_unregister(device);
+	platform_driver_unregister(&amd_hfi_driver);
+}
+module_init(amd_hfi_init);
+module_exit(amd_hfi_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("AMD Hardware Feedback Interface Driver");
-- 
2.45.2.606.g9005149a4a

