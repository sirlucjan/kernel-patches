From 045f11a81aa466de93422418b2ecb42ef0e03a0d Mon Sep 17 00:00:00 2001
From: Torge Matthies <openglfreak@googlemail.com>
Date: Tue, 15 Mar 2022 23:08:54 +0100
Subject: [PATCH 7/7] sched/alt: Add memory barriers around atomics.

---
 kernel/sched/alt_core.c | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index 5e47ebfec..4d7a4e1e5 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -156,10 +156,12 @@ static sched_bitmask_t sched_rq_watermark[NR_CPUS] ____cacheline_aligned_in_smp;
 
 #define x(p, set, mask)                                \
 	do {                                           \
+		smp_mb__before_atomic();               \
 		if (set)                               \
 			atomic_long_or((mask), (p));   \
 		else                                   \
 			atomic_long_and(~(mask), (p)); \
+		smp_mb__after_atomic();                \
 	} while (0)
 
 static __always_inline void sched_rq_watermark_fill_downwards(int cpu, unsigned int end,
@@ -191,7 +193,9 @@ static __always_inline void sched_rq_watermark_fill_downwards(int cpu, unsigned
 	}
 
 	while (end_idx != start_idx) {
+		smp_mb__before_atomic();
 		atomic_long_set(p, set ? ~0UL : 0);
+		smp_mb__after_atomic();
 		p -= 1;
 		end_idx -= 1;
 	}
-- 
2.35.1.354.g715d08a9e5

