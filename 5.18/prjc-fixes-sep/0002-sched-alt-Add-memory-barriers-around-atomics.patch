From 2ca7d68ed3cac91c56b6dce66aa95e672c38c1a5 Mon Sep 17 00:00:00 2001
From: Torge Matthies <openglfreak@googlemail.com>
Date: Tue, 15 Mar 2022 23:08:54 +0100
Subject: [PATCH 2/8] sched/alt: Add memory barriers around atomics.

---
 kernel/sched/alt_core.c | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index 81ff57896..a1b42c203 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -156,10 +156,12 @@ static sched_bitmask_t sched_rq_watermark[NR_CPUS] ____cacheline_aligned_in_smp;
 
 #define x(p, set, mask)                                \
 	do {                                           \
+		smp_mb__before_atomic();               \
 		if (set)                               \
 			atomic_long_or((mask), (p));   \
 		else                                   \
 			atomic_long_and(~(mask), (p)); \
+		smp_mb__after_atomic();                \
 	} while (0)
 
 static __always_inline void sched_rq_watermark_fill_downwards(int cpu, unsigned int end,
@@ -191,7 +193,9 @@ static __always_inline void sched_rq_watermark_fill_downwards(int cpu, unsigned
 	}
 
 	while (end_idx != start_idx) {
+		smp_mb__before_atomic();
 		atomic_long_set(p, set ? ~0UL : 0);
+		smp_mb__after_atomic();
 		p -= 1;
 		end_idx -= 1;
 	}
-- 
2.36.1.74.g277cf0bc36

