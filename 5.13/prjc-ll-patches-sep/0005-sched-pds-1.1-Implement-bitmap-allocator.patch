From cefc41d4c9cda5000904137479a817b7f797ff03 Mon Sep 17 00:00:00 2001
From: Piotr Gorski <lucjan.lucjanov@gmail.com>
Date: Mon, 14 Dec 2020 16:03:36 +0100
Subject: [PATCH 5/6] sched/pds: 1.1 Implement bitmap allocator

Signed-off-by: Piotr Gorski <lucjan.lucjanov@gmail.com>
---
 include/linux/sched.h    |  1 +
 kernel/sched/alt_core.c  | 14 +++---
 kernel/sched/alt_sched.h |  6 +++
 kernel/sched/pds.h       |  9 ++++
 kernel/sched/pds_imp.h   | 92 ++++++++++++++++++++++++++++++++++++++++
 5 files changed, 113 insertions(+), 9 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 4c112a46c88d..d5313fca8ed1 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -728,6 +728,7 @@ struct task_struct {
 	int				sl_level;
 	/* skip list node */
 	struct skiplist_node		sl_node;
+	unsigned int			sln_idx;
 #endif /* CONFIG_SCHED_PDS */
 	/* sched_clock time spent running */
 	u64				sched_time;
diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index 3b40f6e03a29..fc5348e75b26 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -3802,22 +3802,17 @@ static inline void schedule_debug(struct task_struct *prev, bool preempt)
 	schedstat_inc(this_rq()->sched_count);
 }
 
-/*
- * Compile time debug macro
- * #define ALT_SCHED_DEBUG
- */
-
-#ifdef ALT_SCHED_DEBUG
 void alt_sched_debug(void)
 {
+#ifdef ALT_SCHED_DEBUG
 	printk(KERN_INFO "sched: pending: 0x%04lx, idle: 0x%04lx, sg_idle: 0x%04lx\n",
 	       sched_rq_pending_mask.bits[0],
 	       sched_rq_watermark[IDLE_WM].bits[0],
 	       sched_sg_idle_mask.bits[0]);
-}
-#else
-inline void alt_sched_debug(void) {}
+
+	sched_internal_debug();
 #endif
+}
 
 #ifdef	CONFIG_SMP
 
@@ -6661,6 +6656,7 @@ void __init sched_init(void)
 	struct rq *rq;
 
 	printk(KERN_INFO ALT_SCHED_VERSION_MSG);
+	sched_selftest();
 
 	wait_bit_init();
 
diff --git a/kernel/sched/alt_sched.h b/kernel/sched/alt_sched.h
index ac11555ba4f1..d41b6beb68e6 100644
--- a/kernel/sched/alt_sched.h
+++ b/kernel/sched/alt_sched.h
@@ -49,6 +49,11 @@
 
 #include <trace/events/sched.h>
 
+/*
+ * Compile time debug macro
+ * #define ALT_SCHED_DEBUG
+ */
+
 #ifdef CONFIG_SCHED_BMQ
 #include "bmq.h"
 #endif
@@ -147,6 +152,7 @@ struct rq {
 	struct bmq queue;
 #endif
 #ifdef CONFIG_SCHED_PDS
+	struct skiplist_pool sl_pool;
 	struct skiplist_node sl_header;
 #endif
 	unsigned long watermark;
diff --git a/kernel/sched/pds.h b/kernel/sched/pds.h
index 623908cf4380..3d33ee2f883a 100644
--- a/kernel/sched/pds.h
+++ b/kernel/sched/pds.h
@@ -6,4 +6,13 @@
 #define SCHED_BITS	(MAX_RT_PRIO + NICE_WIDTH / 2 + 1)
 #define IDLE_TASK_SCHED_PRIO	(SCHED_BITS - 1)
 
+#define PDS_INDEX_NUM 32UL
+struct skiplist_pool {
+#ifdef ALT_SCHED_DEBUG
+	unsigned long alloc_count;
+	unsigned long alloc_retry_unique;
+	unsigned long alloc_retry_count;
+#endif
+	unsigned long free_bitmap;
+};
 #endif
diff --git a/kernel/sched/pds_imp.h b/kernel/sched/pds_imp.h
index 335ce3a8e3ec..6de20895819c 100644
--- a/kernel/sched/pds_imp.h
+++ b/kernel/sched/pds_imp.h
@@ -1,3 +1,92 @@
+/*
+ * PDS re-implement
+ */
+static void skiplist_pool_init(struct skiplist_pool *slp)
+{
+#ifdef ALT_SCHED_DEBUG
+	slp->alloc_retry_count = 0UL;
+	slp->alloc_retry_unique = 0UL;
+	slp->alloc_count = 0UL;
+#endif
+	slp->free_bitmap = (1UL << PDS_INDEX_NUM) - 1;
+}
+
+static unsigned long skiplist_pool_alloc_index(struct skiplist_pool *slp)
+{
+#ifdef ALT_SCHED_DEBUG
+	int retry = 0;
+	slp->alloc_count++;
+#endif
+	if (slp->free_bitmap) {
+		unsigned long idx = __ffs(slp->free_bitmap);
+		slp->free_bitmap &= ~(1UL << idx);
+
+		return idx;
+	}
+
+	return PDS_INDEX_NUM;
+}
+
+static void skiplist_pool_free_index(struct skiplist_pool *slp,
+				     const unsigned int idx)
+{
+	if (idx >= PDS_INDEX_NUM)
+		return;
+
+	slp->free_bitmap |= (1UL << idx);
+}
+
+static void skiplist_pool_insert(struct rq *rq, struct task_struct *p)
+{
+	p->sln_idx = skiplist_pool_alloc_index(&rq->sl_pool);
+}
+
+static void skiplist_pool_delete(struct rq *rq, struct task_struct *p)
+{
+	skiplist_pool_free_index(&rq->sl_pool, p->sln_idx);
+}
+
+void sched_selftest(void)
+{
+	struct skiplist_pool slp;
+	unsigned int idx[PDS_INDEX_NUM + 1];
+	int i;
+	int count;
+
+	/*
+	 * init skiplist pool
+	 */
+	skiplist_pool_init(&slp);
+
+	printk(KERN_INFO "sched: selftest begin\n");
+	for (count = 0; count < 100000; count++) {
+		for (i = 0; i < PDS_INDEX_NUM + 1; i++)
+			idx[i] = skiplist_pool_alloc_index(&slp);
+		for (i = 0; i < PDS_INDEX_NUM + 1; i++)
+			skiplist_pool_free_index(&slp, idx[i]);
+
+		BUG_ON(((1UL << PDS_INDEX_NUM) - 1 ) != slp.free_bitmap);
+	}
+	printk(KERN_INFO "sched: selftest end\n");
+}
+
+#ifdef ALT_SCHED_DEBUG
+void skiplist_pool_debug(const struct skiplist_pool *slp)
+{
+	printk(KERN_INFO "sched: skiplist_pool alloc %lu/%lu/%lu\n",
+	       slp->alloc_retry_count, slp->alloc_retry_unique,
+	       slp->alloc_count);
+}
+
+void sched_internal_debug(void)
+{
+	int i;
+
+	for (i = 0; i < 8; i++)
+		skiplist_pool_debug(&cpu_rq(i)->sl_pool);
+}
+#endif
+
 #define ALT_SCHED_VERSION_MSG "sched/pds: PDS CPU Scheduler "ALT_SCHED_VERSION" by Alfred Chen.\n"
 
 static const u64 user_prio2deadline[NICE_WIDTH] = {
@@ -111,6 +200,7 @@ DEFINE_SKIPLIST_INSERT_FUNC(pds_skiplist_insert, pds_skiplist_task_search);
 static inline void sched_queue_init(struct rq *rq)
 {
 	INIT_SKIPLIST_NODE(&rq->sl_header);
+	skiplist_pool_init(&rq->sl_pool);
 }
 
 /*
@@ -163,6 +253,7 @@ static inline unsigned long sched_queue_watermark(struct rq *rq)
 	psi_dequeue(p, flags & DEQUEUE_SLEEP);			\
 	sched_info_dequeued(rq, p);				\
 								\
+	skiplist_pool_delete(rq, p);					\
 	if (skiplist_del_init(&rq->sl_header, &p->sl_node)) {	\
 		func;						\
 	}
@@ -171,6 +262,7 @@ static inline unsigned long sched_queue_watermark(struct rq *rq)
 	sched_info_queued(rq, p);					\
 	psi_enqueue(p, flags);						\
 									\
+	skiplist_pool_insert(rq, p);						\
 	p->sl_node.level = p->sl_level;					\
 	pds_skiplist_insert(&rq->sl_header, &p->sl_node)
 
-- 
2.32.0.93.g670b81a890

