From f7c5d4647fc0817c574c50ee22ff5419c2240e37 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Thu, 9 May 2019 21:04:12 +0800
Subject: [PATCH 5/7] bmq: Remove detach_task() and attach_task().

---
 kernel/sched/bmq.c | 52 ++++++++++++----------------------------------
 1 file changed, 13 insertions(+), 39 deletions(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index 393fabe4816f..9c2e0e56e95d 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -1021,37 +1021,6 @@ static inline bool is_cpu_allowed(struct task_struct *p, int cpu)
  *    is done.
  */
 
-/*
- * detach_task() -- detach the task for the migration specified in @target_cpu
- */
-static void detach_task(struct rq *rq, struct task_struct *p, int target_cpu)
-{
-	lockdep_assert_held(&rq->lock);
-
-	p->on_rq = TASK_ON_RQ_MIGRATING;
-	if (task_contributes_to_load(p))
-		rq->nr_uninterruptible++;
-	dequeue_task(p, rq, 0);
-
-	set_task_cpu(p, target_cpu);
-}
-
-/*
- * attach_task() -- attach the task detached by detach_task() to its new rq.
- */
-static void attach_task(struct rq *rq, struct task_struct *p)
-{
-	lockdep_assert_held(&rq->lock);
-
-	BUG_ON(task_rq(p) != rq);
-
-	if (task_contributes_to_load(p))
-		rq->nr_uninterruptible--;
-	enqueue_task(p, rq, 0);
-	p->on_rq = TASK_ON_RQ_QUEUED;
-	cpufreq_update_this_cpu(rq, 0);
-}
-
 /*
  * move_queued_task - move a queued task to new rq.
  *
@@ -1060,16 +1029,19 @@ static void attach_task(struct rq *rq, struct task_struct *p)
 static struct rq *move_queued_task(struct rq *rq, struct task_struct *p, int
 				   new_cpu)
 {
-	detach_task(rq, p, new_cpu);
+	lockdep_assert_held(&rq->lock);
+
+	p->on_rq = TASK_ON_RQ_MIGRATING;
+	dequeue_task(p, rq, 0);
+	set_task_cpu(p, new_cpu);
 	raw_spin_unlock(&rq->lock);
 
 	rq = cpu_rq(new_cpu);
 
 	raw_spin_lock(&rq->lock);
-	update_rq_clock(rq);
-
-	attach_task(rq, p);
-
+	BUG_ON(task_cpu(p) != new_cpu);
+	enqueue_task(p, rq, 0);
+	p->on_rq = TASK_ON_RQ_QUEUED;
 	check_preempt_curr(rq, p);
 
 	return rq;
@@ -2891,8 +2863,9 @@ migrate_pending_tasks(struct rq *rq, struct rq *dest_rq)
 			continue;
 		next = rq_next_bmq_task(p, rq);
 		if (cpumask_test_cpu(dest_cpu, &p->cpus_allowed)) {
-			detach_task(rq, p, dest_cpu);
-			attach_task(dest_rq, p);
+			dequeue_task(p, rq, 0);
+			set_task_cpu(p, dest_cpu);
+			enqueue_task(p, dest_rq, 0);
 			nr_migrated++;
 		}
 		nr_tries--;
@@ -2915,7 +2888,8 @@ lock_and_migrate_pending_tasks(struct rq *src_rq, struct rq *rq)
 	spin_acquire(&src_rq->lock.dep_map, SINGLE_DEPTH_NESTING, 1, _RET_IP_);
 
 	update_rq_clock(src_rq);
-	nr_migrated = migrate_pending_tasks(src_rq, rq);
+	if ((nr_migrated = migrate_pending_tasks(src_rq, rq)))
+		cpufreq_update_this_cpu(rq, 0);
 
 	spin_release(&src_rq->lock.dep_map, 1, _RET_IP_);
 	do_raw_spin_unlock(&src_rq->lock);
-- 
2.22.0.rc1

